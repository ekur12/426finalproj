# -*- coding: utf-8 -*-
"""Style Transfer on Image Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17H0xzx-LVxOfJWCodEZ0E7mPTyu5thyN

# Image Segmentation
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install opencv-python matplotlib
# !pip install 'git+https://github.com/facebookresearch/segment-anything.git'
# !pip install -q roboflow supervision
# 
# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth

import sys
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
import supervision as sv
import cv2
import matplotlib.pyplot as plt
import torch
import numpy as np
import tensorflow as tf
import PIL

assert torch.cuda.is_available(), "No GPU available"

print("GPU found")
device=torch.device("cuda")

MODEL_TYPE = 'vit_h'
sam = sam_model_registry[MODEL_TYPE](checkpoint='sam_vit_h_4b8939.pth')
sam.to(device=device)

def load_image(image_path):
  max_dim = 512
  img = tf.io.read_file(image_path)
  img = tf.image.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)

  #Change shape of image to our size
  shape = tf.cast(tf.shape(img)[:-1], tf.float32)
  long_dim = max(shape)
  scale = max_dim / long_dim

  new_shape = tf.cast(shape * scale, tf.int32)

  img = tf.image.resize(img, new_shape)
  img = img[tf.newaxis, :]
  return img

def tensor2image(tensor):
  tensor = np.array(tensor*255, dtype=np.uint8)
  if np.ndim(tensor)>3:
    assert tensor.shape[0] == 1
    tensor = tensor[0]
  return PIL.Image.fromarray(tensor)

mask_generator = SamAutomaticMaskGenerator(sam)

def get_mask(filepath):
  img = load_image(filepath)
  img = tensor2image(img)
  result = mask_generator.generate(np.array(img))

  masks_full = [
    mask
    for mask in sorted(result, key = lambda x: x['area'], reverse=True)
  ]

  masks = [
    mask['segmentation']
    for mask in sorted(result, key = lambda x: x['area'], reverse=True)
  ]

  print(len(masks))
  sv.plot_images_grid(
      images=masks,
      grid_size = (8, int(len(masks)/8)+1),
      size=(16,16)
  )

  print(masks_full[0]['area'] - masks_full[1]['area'])

  if masks_full[0]['area'] - masks_full[1]['area'] < 100000:
    foreground_mask = masks[0] | masks[1]
  else:
    foreground_mask = masks[0]
  background_mask = 1 - foreground_mask

  return img, foreground_mask, background_mask

def get_styled_image(og_img, styled_img_path, foreground_mask, background_mask):
  styled_img = load_image(styled_img_path)
  styled_img = tensor2image(styled_img)
  size = og_img.size
  styled_img = styled_img.resize((size[0],size[1]))

  final_img = styled_img*foreground_mask[:, :, np.newaxis]
  final_img = final_img + og_img*(background_mask[:, :, np.newaxis])

  return styled_img, final_img

img, foreground_mask, background_mask = get_mask('animal_in_field.jpg')
# img, foreground_mask, background_mask = get_mask('/content/IMG_5122.jpg')

plt.imshow(foreground_mask, cmap='gray')
plt.title('Foreground mask')
plt.axis('off')
plt.show()

plt.imshow(background_mask, cmap='gray')
plt.title('Background mask')
plt.axis('off')
plt.show()

background_mask

styled_img, final_img = get_styled_image(img, 'styled_image.png', foreground_mask, background_mask)

plt.imshow(styled_img)
plt.axis('off')
plt.show()

plt.imshow(final_img)
plt.axis('off')
plt.show()
